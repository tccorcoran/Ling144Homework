{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 1\n",
      "\n",
      "A) For testStr below, write the regular expression `sub` call that replaces all instances of `(sub)` with  `$%\\*$1\\1`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testStr = \"\"\"Down in my sub, I wanted to\n",
      "submit to something (substantial) that wouldn't\n",
      "lead to subalterns calling in{sub}ordination, or anything else\n",
      "that I could (sub).\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import re\n",
      "subRE = re.compile(r'SEARCH')\n",
      "out =  subRE.sub(r'REPLACE', testStr)\n",
      "print out"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Down in my sub, I wanted to\n",
        "submit to something (substantial) that wouldn't\n",
        "lead to subalterns calling in{sub}ordination, or anything else\n",
        "that I could $%\\*$1\\1.\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "B) Now, write another regular expression to substitute `$%\\*$1\\1` with `(sub)`. You'll know you have it right because the output will be identical to `testStr`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "http://chinesefood.about.com/od/tofurecipes/r/stirfriedtofu.htmotherFind = re.compile(r'SEARCH')\n",
      "otherFind.sub('REPLACE', out) == testStr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Problem 2\n",
      "\n",
      "In this directory, I have provided the file `romanticism.txt`. Please open it and read the entire contents into one string. You can use the `read()` method of the file object to do that. \n",
      "\n",
      "Now the format of the file is like this:\n",
      "\n",
      "line 1: a title line, containing a title and then some citational material and/or other stuff\n",
      "\n",
      "line 2: blank \n",
      "\n",
      "line 3: the url of the resource\n",
      "\n",
      "line 4: blank\n",
      "\n",
      "line 5: like line 1\n",
      "\n",
      "line 6: like line 2\n",
      "\n",
      "etc.\n",
      "\n",
      "Your task here is to use regular expressions to make these into proper HTML links. In html, links use the **anchor** tag, like so:\n",
      "\n",
      "    <a href=\"url\" target=\"BLANK\">link text</a>\n",
      "\n",
      "Please save your output in the string `output`. As you can see in the following line, I'm using that name to display the output as HTML using the `HTML` function from `IPython.display`. You obviously can change this code to your liking. I'm just trying to get things to print in a way that is easy to read. [More here](http://nbviewer.ipython.org/urls/raw.github.com/ipython/ipython/1.x/examples/notebooks/Part%205%20-%20Rich%20Display%20System.ipynb)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#open and read file\n",
      "import re\n",
      "fi  = open('romanticism.txt').read()\n",
      "fRE = re.compile(r'(.*?)((\\(|:|,).*)\\n\\n((http|gopher).*)')\n",
      "output =  fRE.sub(r'<a href=\"\\4\" target=\"BLANK\">\\1</a>\\2 <br>', fi)\n",
      "print output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "<a href=\"http://english.ucsb.edu:591/rchrono/\" target=\"BLANK\">Romantic Chronology </a>(UC Santa Barbara & Miami U., Ohio): <br>\n",
        "\n",
        "<a href=\"http://www.lib.ucdavis.edu/English/BWRP/index.htm\" target=\"BLANK\">British Women Romantic Poets</a>, 1789-1832 (U of Cal. Davis): <br>\n",
        "\n",
        "<a href=\"http://www.qub.ac.uk/english/shuttle/rom-chrono/chrono.htm\" target=\"BLANK\">The European Mirror of the Romantic Chronology </a>(Queen's U., Belfast): <br>\n",
        "\n",
        "<a href=\"http://etext.lib.virginia.edu/modeng.browse.html\" target=\"BLANK\">The Modern English Collection at the Electronic Center </a>(UVa) <br>\n",
        "\n",
        "<a href=\"http://etext.lib.virginia.edu/britpo.html\" target=\"BLANK\">British Poetry 1780-1910</a>: A Hypermedia Archive of Scholarly Editions (UVA), co-editor, Jerome McGann: <br>\n",
        "\n",
        "<a href=\"http://jefferson.village.virginia.edu/blake/\" target=\"BLANK\">Blake Archive </a>(hosted at UVA), directed by Morris Eaves, Robert N. Essick, and Joseph Viscomi: <br>\n",
        "\n",
        "<a href=\"gopher://dept.english.upenn.edu:70/11/Courses\" target=\"BLANK\">The UPenn Gopher </a>(with its substantial non-canonical Romantics holdings): <br>\n",
        "\n",
        "<a href=\"gopher://dept.english.upenn.edu/11/E-Text/PEAL\" target=\"BLANK\">also known as PEAL</a>: Penn English Archive and Library <br>\n",
        "\n",
        "<a href=\"http://dept.english.upenn.edu/~mgamer/Romantic/\" target=\"BLANK\">Romantic Links and Home Pages </a>(Univ.of Penna.), Michael Gamer <br>\n",
        "\n",
        "<a href=\"http://gopher.upenn.edu/pennprintout/html/v11/3/creature.html\" target=\"BLANK\">The Frankenstein Project </a>(U. Penn): <br>\n",
        "\n",
        "<a href=\"http://www.rc.umd.edu/\" target=\"BLANK\">Romantic Circles Project </a>(Second-Generation Romantics and Their Circle), major participants, Donald Reiman, Neil Fraistat, Carl Stahmer: <br>\n",
        "\n",
        "<a href=\"http://fay.english.umb.edu/\" target=\"BLANK\">Bluestocking Archive </a>(U. Mass.), Elizabeth Fay: <br>\n",
        "\n",
        "<a href=\"http://www.nottingham.ac.uk/~aezacweb/wrew.htm\" target=\"BLANK\">Romantic Women Writers Page </a>(Nottingham U., U.K.), Adriana Craciun: <br>\n",
        "\n",
        "<a href=\"http://users.ox.ac.uk/~scat0385\" target=\"BLANK\">Romanticism on the Net </a>(Oxford U., England): <br>\n",
        "\n",
        "<a href=\"http://www.ualberta.ca/~dmiall/ROMCDINF.HTM\" target=\"BLANK\">Romanticsm CD-ROM </a>(U. of Alberta): <br>\n",
        "\n",
        "<a href=\"http://www.en.utexas.edu\" target=\"BLANK\">Romanticism at UT Austin</a>, Computer Writing and Research Lab of UT Austin directed by Daniel Anderson: <br>\n",
        "\n",
        "<a href=\"http://www.cwrl.utexas.edu/~worp\" target=\"BLANK\">Women of the Romantic Period </a>(UT Austin), Daniel Anderson and Morri Safran: <br>\n",
        "\n",
        "<a href=\"http://www.usc.edu/dept/LAS/english/19c/newbooks.html\" target=\"BLANK\">New Books in 19th-Century Studies</a>: <br>\n",
        "\n",
        "<a href=\"http://www.luc.edu/publications/keats-shelley/ksjweb.htm\" target=\"BLANK\">The Keats-Shelley Journal Home Page</a>, ed. Steven E. Jones <br>\n",
        "\n",
        "<a href=\"http://lang.nagoya-u.ac.jp/~matsuoka/19th-authors.html\" target=\"BLANK\">19th Century British and Irish Authors</a>, Mitsuharu Matsuoka (Nagoya University): <br>\n",
        "\n",
        "<a href=\"http://lang.nagoya-u.ac.jp/~matsuoka/Victorian.html\" target=\"BLANK\">Victorian Web Sites</a>, Mitsuharu Matsuoka (Nagoya University): <br>\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML(output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<a href=\"http://english.ucsb.edu:591/rchrono/\" target=\"BLANK\">Romantic Chronology </a>(UC Santa Barbara & Miami U., Ohio): <br>\n",
        "\n",
        "<a href=\"http://www.lib.ucdavis.edu/English/BWRP/index.htm\" target=\"BLANK\">British Women Romantic Poets</a>, 1789-1832 (U of Cal. Davis): <br>\n",
        "\n",
        "<a href=\"http://www.qub.ac.uk/english/shuttle/rom-chrono/chrono.htm\" target=\"BLANK\">The European Mirror of the Romantic Chronology </a>(Queen's U., Belfast): <br>\n",
        "\n",
        "<a href=\"http://etext.lib.virginia.edu/modeng.browse.html\" target=\"BLANK\">The Modern English Collection at the Electronic Center </a>(UVa) <br>\n",
        "\n",
        "<a href=\"http://etext.lib.virginia.edu/britpo.html\" target=\"BLANK\">British Poetry 1780-1910</a>: A Hypermedia Archive of Scholarly Editions (UVA), co-editor, Jerome McGann: <br>\n",
        "\n",
        "<a href=\"http://jefferson.village.virginia.edu/blake/\" target=\"BLANK\">Blake Archive </a>(hosted at UVA), directed by Morris Eaves, Robert N. Essick, and Joseph Viscomi: <br>\n",
        "\n",
        "<a href=\"gopher://dept.english.upenn.edu:70/11/Courses\" target=\"BLANK\">The UPenn Gopher </a>(with its substantial non-canonical Romantics holdings): <br>\n",
        "\n",
        "<a href=\"gopher://dept.english.upenn.edu/11/E-Text/PEAL\" target=\"BLANK\">also known as PEAL</a>: Penn English Archive and Library <br>\n",
        "\n",
        "<a href=\"http://dept.english.upenn.edu/~mgamer/Romantic/\" target=\"BLANK\">Romantic Links and Home Pages </a>(Univ.of Penna.), Michael Gamer <br>\n",
        "\n",
        "<a href=\"http://gopher.upenn.edu/pennprintout/html/v11/3/creature.html\" target=\"BLANK\">The Frankenstein Project </a>(U. Penn): <br>\n",
        "\n",
        "<a href=\"http://www.rc.umd.edu/\" target=\"BLANK\">Romantic Circles Project </a>(Second-Generation Romantics and Their Circle), major participants, Donald Reiman, Neil Fraistat, Carl Stahmer: <br>\n",
        "\n",
        "<a href=\"http://fay.english.umb.edu/\" target=\"BLANK\">Bluestocking Archive </a>(U. Mass.), Elizabeth Fay: <br>\n",
        "\n",
        "<a href=\"http://www.nottingham.ac.uk/~aezacweb/wrew.htm\" target=\"BLANK\">Romantic Women Writers Page </a>(Nottingham U., U.K.), Adriana Craciun: <br>\n",
        "\n",
        "<a href=\"http://users.ox.ac.uk/~scat0385\" target=\"BLANK\">Romanticism on the Net </a>(Oxford U., England): <br>\n",
        "\n",
        "<a href=\"http://www.ualberta.ca/~dmiall/ROMCDINF.HTM\" target=\"BLANK\">Romanticsm CD-ROM </a>(U. of Alberta): <br>\n",
        "\n",
        "<a href=\"http://www.en.utexas.edu\" target=\"BLANK\">Romanticism at UT Austin</a>, Computer Writing and Research Lab of UT Austin directed by Daniel Anderson: <br>\n",
        "\n",
        "<a href=\"http://www.cwrl.utexas.edu/~worp\" target=\"BLANK\">Women of the Romantic Period </a>(UT Austin), Daniel Anderson and Morri Safran: <br>\n",
        "\n",
        "<a href=\"http://www.usc.edu/dept/LAS/english/19c/newbooks.html\" target=\"BLANK\">New Books in 19th-Century Studies</a>: <br>\n",
        "\n",
        "<a href=\"http://www.luc.edu/publications/keats-shelley/ksjweb.htm\" target=\"BLANK\">The Keats-Shelley Journal Home Page</a>, ed. Steven E. Jones <br>\n",
        "\n",
        "<a href=\"http://lang.nagoya-u.ac.jp/~matsuoka/19th-authors.html\" target=\"BLANK\">19th Century British and Irish Authors</a>, Mitsuharu Matsuoka (Nagoya University): <br>\n",
        "\n",
        "<a href=\"http://lang.nagoya-u.ac.jp/~matsuoka/Victorian.html\" target=\"BLANK\">Victorian Web Sites</a>, Mitsuharu Matsuoka (Nagoya University): <br>\n",
        "\n"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "<IPython.core.display.HTML at 0x9bfb4ec>"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 3\n",
      "\n",
      "The file `ssns.txt` contains a raw text grab of the geneology website [SortedByName](http://sortedbyname.com). You can have a look. Your job in this problem is to convert that raw list of text into a list of dictionaries, of the following sort:\n",
      "\n",
      "    {\"last\": \"Abrams\", \"first\": \"Bobby\", \"born\": \"23 December 1929\", \"died\": \"03 September 2003\", \"ssn\": \"231-28-2235\"}\n",
      "    \n",
      "Note that as someone without a middle name, I don't care to store them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def skip(line):\n",
      "    \"\"\"this is a series of statements about what kind of lines have junk in them\"\"\"\n",
      "    return 0\n",
      "\n",
      "#open file, set it to f\n",
      "name = re.compile(r'[A-Z]+,[A-Z]+') \n",
      "born = re.compile(r'born(( (about|ABT \\d\\d\\d\\d))| \\d?\\d [A-Z]\\w+ \\d\\d\\d\\d)')\n",
      "died = re.compile(r'died(( (about|ABT \\d\\d\\d\\d))| \\d?\\d [A-Z]\\w+ \\d\\d\\d\\d)')\n",
      "ssn = re.compile(r'\\d\\d\\d-\\d\\d-\\d\\d\\d\\d')\n",
      "         \n",
      "results = []\n",
      "for li in f:\n",
      "    if skip(li):\n",
      "        continue\n",
      "    newPerson = {}\n",
      "\n",
      "    match = name.search(li)\n",
      "    if match: #it found something\n",
      "        newPerson[\"first\"] = name.groups()[0]\n",
      "        newPerson[\"last\"] = name.groups()[1]\n",
      "\n",
      "    #etc.\n",
      "    \n",
      "    #add newPerson to results\n",
      "print results"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{'born': '23 December 1929', 'ssn': '231-28-2235', 'last': 'Abrams', 'died': '03 September 2003', 'first': 'Bobby'}, {'born': 'ABT 1932', 'last': 'Abrams', 'first': 'Bobby'}, {'born': '20 October 1940', 'ssn': '412-70-1845', 'last': 'Abrams', 'died': '19 February 2011', 'first': 'Bobby'}, {'born': '30 January 1930', 'ssn': '273-28-0459', 'last': 'Abrams', 'died': '02 December 2003', 'first': 'Bobby'}, {'born': '28 August 1931', 'ssn': '448-28-7333', 'last': 'Abrams', 'died': '15 January 2009', 'first': 'Bob'}, {'born': '10 November 1910', 'ssn': '247-10-8958', 'last': 'Abrams', 'died': 'November 1974', 'first': 'Boisy'}, {'born': '08 September 1954', 'ssn': '187-46-0582', 'last': 'Abrams', 'died': '09 February 2007', 'first': 'Bolden'}, {'born': '21 January 1934', 'ssn': '182-26-7882', 'last': 'Abrams', 'died': '11 March 2008', 'first': 'Bolden'}, {'born': '10 June 1906', 'ssn': '459-46-8859', 'last': 'Abrams', 'died': 'March 1983', 'first': 'Bonnie'}, {'born': '16 April 1941', 'ssn': '356-34-0421', 'last': 'Abrams', 'died': '13 January 2000', 'first': 'Bonnie'}, {'born': 'ABT 1959', 'last': 'Abrams', 'first': 'Bonnie'}, {'born': '15 May 1891', 'ssn': '065-05-8195', 'last': 'Abrams', 'died': 'February 1980', 'first': 'Boris'}, {'born': '08 March 1927', 'ssn': '493-32-9021', 'last': 'Abrams', 'died': '22 June 2001', 'first': 'Boris'}, {'born': '26 March 1914', 'ssn': '419-09-7246', 'last': 'Abrams', 'died': 'May 1988', 'first': 'Bose'}, {'born': 'ABT 1890', 'last': 'Abrams', 'first': 'Bosey'}, {'born': '10 March 1920', 'ssn': '297-05-5931', 'last': 'Abrams', 'died': '22 May 1989', 'first': 'Boyd'}, {'born': '17 January 1903', 'ssn': '317-14-9691', 'last': 'Abrams', 'died': '29 June 1995', 'first': 'Boyd'}, {'born': '23 November 1915', 'ssn': '277-14-8828', 'last': 'Abrams', 'died': '01 April 1991', 'first': 'Boyd'}, {'born': '04 March 1899', 'ssn': '192-28-5193', 'last': 'Abrams', 'died': 'November 1957', 'first': 'Bradley'}, {'born': 'ABT 1971', 'last': 'Abrams', 'first': 'Brenda'}, {'born': 'ABT 1957', 'last': 'Abrams', 'first': 'Brenda'}, {'born': 'ABT 1957', 'last': 'Abrams', 'first': 'Brenda'}, {'born': '06 May 1947', 'ssn': '102-40-0129', 'last': 'Abrams', 'died': '04 April 2011', 'first': 'Brenda'}, {'born': '31 July 1960', 'ssn': '055-56-2703', 'last': 'Abrams', 'died': '13 May 2006', 'first': 'Brenda'}, {'born': '25 May 1955', 'ssn': '518-70-2249', 'last': 'Abrams', 'died': '13 September 2002', 'first': 'Brent'}, {'born': '31 October 1969', 'ssn': '059-62-0759', 'last': 'Abrams', 'died': '02 June 1989', 'first': 'Brian'}, {'born': 'ABT 1954', 'last': 'Abrams', 'first': 'Brian'}, {'born': '10 June 1964', 'ssn': '118-62-4999', 'last': 'Abrams', 'died': '06 August 2013', 'first': 'Brian'}, {'born': '02 June 1959', 'ssn': '314-72-7401', 'last': 'Abrams', 'died': '20 November 2007', 'first': 'Brian'}, {'born': '16 December 1937', 'ssn': '334-30-0087', 'last': 'Abrams', 'died': '05 March 2008', 'first': 'Brian'}, {'born': '22 April 1956', 'ssn': '329-54-9562', 'last': 'Abrams', 'died': '03 July 2003', 'first': 'Brian'}, {'born': '19 February 1962', 'ssn': '549-11-5463', 'last': 'Abrams', 'died': '05 December 2007', 'first': 'Brian'}, {'born': '02 December 1952', 'ssn': '266-88-5504', 'last': 'Abrams', 'died': '23 November 1997', 'first': 'Brian'}, {'born': '05 October 1908', 'ssn': '064-16-1504', 'last': 'Abrams', 'died': '28 November 2000', 'first': 'Bronny'}, {'born': '19 October 1903', 'ssn': '112-18-8415', 'last': 'Abrams', 'died': '10 December 1999', 'first': 'Broucha'}, {'born': '01 February 1942', 'ssn': '247-70-0202', 'last': 'Abrams', 'died': 'October 1972', 'first': 'Bruce'}, {'born': '10 April 1938', 'ssn': '403-52-1002', 'last': 'Abrams', 'died': '13 November 2006', 'first': 'Bruce'}, {'born': '11 June 1946', 'ssn': '017-34-5842', 'last': 'Abrams', 'died': '29 January 2010', 'first': 'Bruce'}, {'born': '17 April 1954', 'ssn': '407-84-6662', 'last': 'Abrams', 'died': '14 August 2002', 'first': 'Bruce'}, {'born': '23 June 1950', 'ssn': '125-38-9925', 'last': 'Abrams', 'died': 'March 1987', 'first': 'Bruce'}, {'last': 'Abrams', 'first': 'Bruce'}, {'born': '20 August 1961', 'ssn': '350-60-8473', 'last': 'Abrams', 'died': '12 December 1999', 'first': 'Bruce'}, {'born': 'ABT 1947', 'last': 'Abrams', 'first': 'Bruce'}, {'born': 'ABT 1947', 'last': 'Abrams', 'first': 'Bruce'}, {'born': 'ABT 1955', 'last': 'Abrams', 'first': 'Bruce'}, {'born': '02 September 1994', 'ssn': '159-76-1092', 'last': 'Abrams', 'died': '26 March 2012', 'first': 'Bryan'}, {'born': '25 January 1918', 'ssn': '571-36-8819', 'last': 'Abrams', 'died': 'August 1977', 'first': 'Bryce'}, {'born': 'ABT 1939', 'last': 'Abrams', 'first': 'Bud'}, {'last': 'Abrams', 'first': 'Bud'}, {'born': '26 July 1929', 'ssn': '214-26-8819', 'last': 'Abrams', 'died': '09 January 2000', 'first': 'Budell'}, {'born': '30 May 1951', 'ssn': '421-70-3383', 'last': 'Abrams', 'died': '24 August 2007', 'first': 'Bud'}, {'born': '15 November 1910', 'ssn': '225-28-2842', 'last': 'Abrams', 'died': 'July 1986', 'first': 'Bufer'}, {'last': 'Abrams', 'first': 'Bufus'}, {'born': '01 April 1932', 'ssn': '400-40-1862', 'last': 'Abrams', 'died': '08 April 2013', 'first': 'Burgess'}, {'born': '08 July 1945', 'ssn': '416-66-9028', 'last': 'Abrams', 'died': 'January 1970', 'first': 'Burke'}, {'born': '10 May 1971', 'ssn': '324-76-9687', 'last': 'Abrams', 'died': '28 March 1995', 'first': 'Burke'}, {'born': '30 October 1911', 'ssn': '400-32-3391', 'last': 'Abrams', 'died': '12 November 2010', 'first': 'Burnace'}, {'born': '17 May 1935', 'ssn': '403-48-4886', 'last': 'Abrams', 'died': '03 November 1996', 'first': 'Burton'}, {'born': '22 July 1926', 'ssn': '288-22-7662', 'last': 'Abrams', 'died': '15 August 1994', 'first': 'Burton'}, {'born': '03 November 1923', 'ssn': '084-14-3261', 'last': 'Abrams', 'died': '23 September 1994', 'first': 'Burton'}, {'born': '19 December 1935', 'ssn': '098-28-4367', 'last': 'Abrams', 'died': '10 November 1995', 'first': 'Burton'}, {'born': '14 September 1893', 'ssn': '422-18-9832', 'last': 'Abrams', 'died': 'September 1972', 'first': 'Byron'}, {'born': '16 April 1929', 'ssn': '416-34-7145', 'last': 'Abrams', 'died': '27 March 2007', 'first': 'Byron'}, {'born': '02 October 1954', 'ssn': '016-48-3855', 'last': 'Abrams', 'died': 'December 1992', 'first': 'C'}, {'born': '09 December 1933', 'ssn': '096-26-1173', 'last': 'Abrams', 'died': '15 December 1988', 'first': 'C'}, {'born': '12 July 1910', 'ssn': '523-09-7536', 'last': 'Abrams', 'died': 'April 1974', 'first': 'C'}, {'born': '13 October 1948', 'ssn': '107-40-1063', 'last': 'Abrams', 'died': 'March 1993', 'first': 'C'}, {'born': '14 January 1929', 'ssn': '129-38-0800', 'last': 'Abrams', 'died': 'January 1988', 'first': 'C'}, {'born': '16 March 1900', 'ssn': '290-28-7837', 'last': 'Abrams', 'died': 'February 1971', 'first': 'C'}, {'born': '22 October 1905', 'ssn': '442-03-2743', 'last': 'Abrams', 'died': 'September 1982', 'first': 'C'}, {'born': '26 January 1941', 'ssn': '233-64-9421', 'last': 'Abrams', 'died': '15 August 1991', 'first': 'C'}, {'born': '27 March 1882', 'ssn': '558-10-8299', 'last': 'Abrams', 'died': 'December 1963', 'first': 'C'}, {'born': '25 April 1912', 'ssn': '072-16-8326', 'last': 'Abrams', 'died': '16 March 1995', 'first': 'Calbraith'}, {'born': 'ABT 1859', 'last': 'Abrams', 'first': 'Calista'}, {'born': '01 July 1913', 'ssn': '327-01-8229', 'last': 'Abrams', 'died': 'January 1981', 'first': 'Calvin'}, {'born': '03 August 1939', 'ssn': '357-32-9977', 'last': 'Abrams', 'died': '16 February 2013', 'first': 'Calvin'}, {'born': '15 January 1927', 'ssn': '204-14-0422', 'last': 'Abrams', 'died': '14 September 2002', 'first': 'Calvin'}, {'born': '02 March 1924', 'ssn': '100-12-2480', 'last': 'Abrams', 'died': '25 February 1997', 'first': 'Calvin'}, {'born': '04 February 1914', 'ssn': '335-01-4627', 'last': 'Abrams', 'died': '31 December 1994', 'first': 'Camille'}, {'born': '08 October 1934', 'ssn': '319-30-5646', 'last': 'Abrams', 'died': '14 February 2011', 'first': 'Candida'}, {'born': 'ABT 1969', 'last': 'Abrams', 'first': 'Candina'}, {'born': 'ABT 1968', 'last': 'Abrams', 'first': 'Candus'}, {'born': '22 February 1914', 'ssn': '263-16-5419', 'last': 'Abrams', 'died': 'February 1970', 'first': 'Canna'}, {'born': '06 August 1911', 'ssn': '441-36-1249', 'last': 'Abrams', 'died': '19 November 2010', 'first': 'Captiolia'}, {'born': '02 February 1880', 'ssn': '292-10-3526', 'last': 'Abrams', 'died': 'June 1967', 'first': 'Carl'}, {'born': '03 April 1893', 'ssn': '562-10-5868', 'last': 'Abrams', 'died': 'November 1975', 'first': 'Carl'}, {'born': '03 June 1914', 'ssn': '063-03-6276', 'last': 'Abrams', 'died': 'July 1977', 'first': 'Carl'}, {'born': '04 February 1917', 'ssn': '275-16-3319', 'last': 'Abrams', 'died': 'February 1977', 'first': 'Carl'}, {'born': '04 February 1918', 'ssn': '427-14-1672', 'last': 'Abrams', 'died': '04 April 1985', 'first': 'Carl'}]\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 4\n",
      "\n",
      "Write function `addHTMLTag` so that it wraps every instance of `word` in `string` with tag `tag`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def addHTMLbold(word, string, tag):\n",
      "    \"\"\"this looks for word in string, and wraps all occurrences with tag and end_tag\"\"\"\n",
      "    wordRE = re.compile(r'SEARCH')\n",
      "    # you will need to set up some stuff here...\n",
      "    \n",
      "    #loop through the matches to the string one at a time\n",
      "    for m in wordRE.finditer(string):\n",
      "        found = string[m.start():m.end()]\n",
      "        \n",
      "        #now use a format to get the tagged text\n",
      "        \n",
      "        #and add the tagged part\n",
      "\n",
      "    #here, don't forget to add the start of the string, the end, and whatever is in between the matches\n",
      "    return string #change this!!!!\n",
      "\n",
      "mod = addHTMLbold(\"test\", \"This is a test testy to see what testy retests test out\", \"em\")\n",
      "HTML(mod)\n",
      "mod2 = addHTMLbold(\"is\", mod, \"strong\")\n",
      "HTML(mod2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "This <strong>is</strong> a <em>test</em> testy to see what testy retests <em>test</em> out"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "<IPython.core.display.HTML at 0x1022cf890>"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Problem 5\n",
      "\n",
      "A) Write a function `splitWithHTML` that tokenizes a text string on HTML tags, keeping the HTML tags in the tokens"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def splitWithHTML(text):\n",
      "    vs =re.split(r'SEARCH', text)\n",
      "    print vs\n",
      "\n",
      "text = \"\"\"\n",
      "<html>\n",
      "<head><title>This is the title</title>\n",
      "<body onload=\"javascript blah blah>>\">This is what <b>is happening <i> to us</i></b></body>\n",
      "<html>\"\"\"\n",
      "\n",
      "splitWithHTML(text)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['\\n', '<html>', '\\n', '<head>', '', '<title>', 'This is the title', '</title>', '\\n', '<body onload=\"javascript blah blah>>\">', 'This is what ', '<b>', 'is happening ', '<i>', ' to us', '</i>', '', '</b>', '', '</body>', '\\n', '<html>', '']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Problem 6\n",
      "\n",
      "The file `roster.txt` contains the 144 class roster, essentially as a receive it from AIS. Please rewrite each line to show the following elements in the following order: \n",
      "\n",
      "    email address[tab]last name[tab]major1\n",
      "   \n",
      "Note that for the tabs, you should know that the way to find/print them is `\\t`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#there are three basic patterns to search for; do them each\n",
      "splitRE = re.compile(r'(?:PATTERN1|PATTERN2|PATTERN3)')\n",
      "#open file as f\n",
      "for li in f:\n",
      "    # use split\n",
      "    \n",
      "    # and print\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "crjimene@ucsc.edu\tRenee\tLINGBA\n",
        "mikovach@ucsc.edu\tIlona\tLANGBA\n",
        "scweiser@ucsc.edu\tClaire\tPHYSBS\n",
        "jahuizar@ucsc.edu\tAnita\tLINGBA\n",
        "matitone@ucsc.edu\tAnthony\tLINGBA\n",
        "srubenki@ucsc.edu\tRae\tLANGBA\n",
        "mcmata@ucsc.edu\tChristopher\tLINGBA\n",
        "vvanegas@ucsc.edu\tValentina\tLINGBA\n",
        "wmbuchan@ucsc.edu\tMichael\tLINGBA\n",
        "lrchan@ucsc.edu\tRebecca\tLINGBA\n",
        "sfsander@ucsc.edu\tFrancine\tLINGBA\n",
        "shmbianc@ucsc.edu\tMichael\tLINGBA\n",
        "sewinn@ucsc.edu\tEugene\tLINGBA\n",
        "skano@ucsc.edu\t\tLINGBA\n",
        "eswong@ucsc.edu\tStanley Gordon\tLINGBA\n",
        "tcorcora@ucsc.edu\tChase\tLINGBA\n",
        "ksheets@ucsc.edu\tAnne\tLINGBA\n",
        "arzavala@ucsc.edu\tRandall\tLINGBA\n",
        "sclothie@ucsc.edu\tLabou\tLINGBA\n",
        "neggert@ucsc.edu\tWilliam\tPHILBA\n",
        "rastle@ucsc.edu\tNicolle\tLINGBA\n",
        "chanmill@ucsc.edu\tAnn\tLINGBA\n",
        "sneace@ucsc.edu\tRachelle\tLINGBA\n",
        "stgarcia@ucsc.edu\tTrevino\tLINGBA\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 7\n",
      "\n",
      "I have extracted the first few paragraphs of [the following](http://www.latimes.com/business/la-fi-obamacare-oversold-20131030,0,558878.story#axzz2jBmVwJij) and put it in `healthcare.txt`. Your job is to split this into sentences; I have `healthcare-sentences.txt` as an answer key.\n",
      "\n",
      "For this, you probably want to find the boundaries and then merge them backwards. Another approach is to use a bunch of lookbehind tests. Unfortunately, you can't combine them into one big lookbehind because Python requires lookahead/behind to be constant width patterns. In this case, you'll need two different lookarounds.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#open file and read in contents as one string\n",
      "\n",
      "#use split\n",
      "sentenceBoundaries = re.compile(r'(PATTERN)')\n",
      "\n",
      "#and then put the sentence boundary back together with the preceding element"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "As the pitchman for his landmark healthcare law, President Obama promised to make buying insurance as easy as buying a plane ticket online or a \"TV on Amazon.\"\n",
        " \n",
        "It would be simple, he said.\n",
        " \n",
        "If there were problems, the president predicted, they would be \"glitches.\"\n",
        " \n",
        "And he said, \"If you like the plan you have, you can keep it.\"\n",
        " \n",
        "Such claims have come back to haunt the president and his allies less than a month into the launch of the online insurance marketplaces at the heart of his healthcare legislation.\n",
        " \n",
        "With the federal website hobbled by bad design and thousands of policyholders receiving cancellation notices, Obama's promises are not being met \u2014 prompting charges of deception from some Republicans and concessions from some allies that elements of the law were oversold.\n",
        " \n",
        "The fallout is only the latest chapter in this White House's three-year struggle to sell the public on the Affordable Care Act, which could come to define the president's legacy.\n",
        " \n",
        "Since signing it into law, the president has variously defended it, promoted it, simplified it and hyped it.\n",
        " \n",
        "But polling shows he has never fully sold, nor educated, the public on the vast new government healthcare program.\n",
        " \n",
        "Publicly, the White House continued Tuesday to defend the president's pre-launch salesmanship.\n",
        " \n",
        "\"The purpose here wasn't to do anything beyond encourage people to make themselves aware of the options available to them,\" White House Press Secretary Jay Carney said.\n",
        " \n",
        "Behind closed doors, some officials who worked on the rollout say they wish they'd left themselves a little wiggle room.\n",
        " \n",
        "They could have done more to play up ways to sign up other than through the website, such as the call centers, said one official, requesting anonymity to discuss the planning process.\n",
        " \n",
        "After taking heat from allies for not finding a crisp way to explain the complex law, the White House tried to boil it down to its simplest elements, the official said, and some nuance was inevitably lost.\n",
        " \n",
        "The first administration official to testify before Congress on the matter apologized Tuesday, saying, \"the website has not worked as well as it should.\"\n",
        " \n",
        "\"This initial experience has not lived up to our expectations or the expectations of the American people, and it is not acceptable,\" Marilyn Tavenner, the head of the federal Centers for Medicare and Medicaid Services, told the House Ways and Means Committee.\n",
        " \n",
        "Tavenner's agency oversaw the development of the site, intended to link consumers with affordable private health insurance plans that meet standards outlined in the 2010 law.\n",
        " \n",
        "Tavenner vowed that the site would be running smoothly by the end of November, in time for consumers to enroll before the new year.\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Problem 8\n",
      "\n",
      "find how many times a regular verb is used in a text, organized by tense (To be completed)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}